{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d620b9d",
   "metadata": {},
   "source": [
    "Finetuned - ChemBERTa + SVR (EmSVR-BACE): pIC50 Prediction Pipeline  \n",
    "----------------------------------------- \n",
    "\n",
    "\n",
    "- Generates ChemBERTa embeddings from SMILES\n",
    "- Selects key features based on a LASSO feature index list \n",
    "- Predicts pIC50 using a EmSVR-BACE model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46f7543c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ./Finetuned_ChemBERTa_Model and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Using device: cpu\n",
      " Random state set to 42\n",
      "\n",
      " 1. Loading fine-tuned ChemBERTa model...\n",
      " Model loaded successfully!\n",
      "\n",
      "2. Reading SMILES from: SMILES.csv\n",
      " Loaded 500 SMILES molecules.\n",
      "\n",
      "3. Generating ChemBERTa embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 500/500 [00:18<00:00, 27.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to: outputs/generated_embeddings.csv\n",
      "\n",
      "4. Selecting features from LASSO indices in: Feature selected by lasso_115.csv\n",
      "Filtered features saved to: outputs/EmSVR-BACE-Features.csv\n",
      "Saved 115 columns out of 115 successfully!\n",
      "\n",
      "5. Loading SVR model from: EmSVR-BACE.joblib\n",
      "6. Predicting pIC50 values...\n",
      "7. Prediction completed! Results saved to: outputs/final_predicted_pIC50.csv\n",
      "\n",
      "8. Sample predictions:\n",
      "                                           SMILES  predicted_pIC50\n",
      "0                          Oc1ccc(cc1)CC([NH3+])C         3.316924\n",
      "1                           Oc1ccc(cc1CC)CC[NH3+]         3.597867\n",
      "2                       Fc1ccc(cc1)CC1CC[NH2+]CC1         3.722697\n",
      "3  Clc1cc2CC(N=C(NC(Cc3ccccc3)c3ncccn3)c2cc1)(C)C         6.057023\n",
      "4   O1[C@@H]2COCC[C@@]2(N=C1N)c1cc(ccc1)-c1cncnc1         6.233910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# Configuration\n",
    "\n",
    "# Here we take 500 smiles from MoleculeNet and predicted their IC50 values using our EmSVR-BACE model. \n",
    "# Note these SMILES are not in our training and test set.\n",
    "\n",
    "input_smiles_csv = \"SMILES.csv\"                                     # keep your smiles in a csv file with the header \"SMILES\". \n",
    "Lasso_features = \"Feature selected by lasso_115.csv\"                # This file has 115 top features based on Lasso regression\n",
    "finetuned_model_path = \"./Finetuned_ChemBERTa_Model\"                # ChemBERTa finetuned Model path\n",
    "svr_model_file = \"EmSVR-BACE.joblib\"                                # EmSVR-BACE model\n",
    "embeddings_csv = \"outputs/generated_embeddings.csv\"\n",
    "filtered_features_csv = \"outputs/EmSVR-BACE-Features.csv\"\n",
    "output_csv = \"outputs/final_predicted_pIC50.csv\"\n",
    "random_state = 42\n",
    "\n",
    "# Create output folder\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "\n",
    "# Reproducibility\n",
    "\n",
    "torch.manual_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "random.seed(random_state)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(random_state)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\n Using device: {device}\")\n",
    "print(f\" Random state set to {random_state}\\n\")\n",
    "\n",
    "\n",
    "# Load ChemBERTa\n",
    "\n",
    "print(\" 1. Loading fine-tuned ChemBERTa model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(finetuned_model_path)\n",
    "model = AutoModel.from_pretrained(finetuned_model_path)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\" Model loaded successfully!\\n\")\n",
    "\n",
    "\n",
    "# Load SMILES\n",
    "\n",
    "print(f\"2. Reading SMILES from: {input_smiles_csv}\")\n",
    "df_smiles = pd.read_csv(input_smiles_csv)\n",
    "if \"SMILES\" not in df_smiles.columns:\n",
    "    raise ValueError(\"Input CSV must contain a column named 'SMILES'.\")\n",
    "smiles_list = df_smiles[\"SMILES\"].tolist()\n",
    "print(f\" Loaded {len(smiles_list)} SMILES molecules.\\n\")\n",
    "\n",
    "\n",
    "# Generate embeddings\n",
    "\n",
    "embeddings = []\n",
    "print(\"3. Generating ChemBERTa embeddings...\")\n",
    "with torch.no_grad():\n",
    "    for smile in tqdm(smiles_list, desc=\"Extracting embeddings\"):\n",
    "        try:\n",
    "            inputs = tokenizer(\n",
    "                smile,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "            ).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "            embeddings.append(cls_embedding.cpu().squeeze().numpy())\n",
    "        except:\n",
    "            embeddings.append(np.zeros(model.config.hidden_size))\n",
    "\n",
    "embeddings_df = pd.DataFrame(embeddings)\n",
    "embeddings_df.to_csv(embeddings_csv, index=False)\n",
    "print(f\"Embeddings saved to: {embeddings_csv}\\n\")\n",
    "\n",
    "\n",
    "# Feature selection using LASSO indices\n",
    "\n",
    "print(f\"4. Selecting features from LASSO indices in: {Lasso_features}\")\n",
    "columns_df = pd.read_csv(Lasso_features)  # header exists\n",
    "columns_to_keep = columns_df.iloc[:, 0].astype(int).tolist() \n",
    "max_index = embeddings_df.shape[1]\n",
    "valid_indices = [i for i in columns_to_keep if i < max_index]\n",
    "\n",
    "if not valid_indices:\n",
    "    raise ValueError(\"No matching columns found! Check your LASSO indices.\")\n",
    "\n",
    "filtered_df = embeddings_df.iloc[:, valid_indices]\n",
    "filtered_df.to_csv(filtered_features_csv, index=False)\n",
    "print(f\"Filtered features saved to: {filtered_features_csv}\")\n",
    "print(f\"Saved {len(valid_indices)} columns out of {len(columns_to_keep)} successfully!\\n\")\n",
    "\n",
    "\n",
    "# Load SVR model and predict\n",
    "\n",
    "print(f\"5. Loading SVR model from: {svr_model_file}\")\n",
    "svr_model = joblib.load(svr_model_file)\n",
    "\n",
    "filtered_df = filtered_df.astype(float)\n",
    "print(\"6. Predicting pIC50 values...\")\n",
    "predictions = svr_model.predict(filtered_df)\n",
    "\n",
    "output_df = df_smiles.copy()\n",
    "output_df[\"predicted_pIC50\"] = predictions\n",
    "output_df.to_csv(output_csv, index=False)\n",
    "print(f\"7. Prediction completed! Results saved to: {output_csv}\\n\")\n",
    "print(\"8. Sample predictions:\")\n",
    "print(output_df[[\"SMILES\", \"predicted_pIC50\"]].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
